---
title: "Dynamic Hand Gesture-Featured Human Motor Adaptation in Tool Delivery using Voice Recognition"
collection: publications
permalink: /publication/dynamic_hand_arxiv
excerpt: 'This paper is about hand-gesture based huam robot interaction. teleoperation and larger human subject experimemt is left for future work.'
date: 2023-09-20
venue: 'arXix preprint'
paperurl: #'https://arxiv.org/pdf/2309.11368.pdf'
citation: 'Fei, H., Tedeschi, S., Huang, Y., Kennedy, A., Wang, Z. (2023). &quot;Dynamic Hand Gesture-Featured Human Motor Adaptation in Tool Delivery using Voice Recognition.&quot; <i>arXiv preprint 1</i>. arXiv:2309.11368.'
---
This paper is about hand-gesture based huam robot interaction. teleoperation and larger human subject experimemt is left for future work.

[Download paper here](https://arxiv.org/pdf/2309.11368.pdf)

**Abstract:**

Human-robot collaboration has benefited users with higher efficiency towards interactive tasks. Nev- ertheless, most collaborative schemes rely on complicated human-machine interfaces, which might lack the requisite intuitiveness compared with natural limb control. We also expect to understand human intent with low training data requirements. In response to these challenges, this paper intro- duces an innovative human-robot collaborative framework that seamlessly integrates hand gesture and dynamic movement recognition, voice recognition, and a switchable control adaptation strat- egy. These modules provide a user-friendly approach that enables the robot to deliver the tools as per user need, especially when the user is working with both hands. Therefore, users can focus on their task execution without additional training in the use of human-machine interfaces, while the robot interprets their intuitive gestures. The proposed multimodal interaction framework is ex- ecuted in the UR5e robot platform equipped with a RealSense D435i camera, and the effectiveness is assessed through a soldering circuit board task. The experiment results have demonstrated su- perior performance in hand gesture recognition, where the static hand gesture recognition module achieves an accuracy of 94.3%, while the dynamic motion recognition module reaches 97.6% accu- racy. Compared with human solo manipulation, the proposed approach facilitates higher efficiency tool delivery, without significantly distracting from human intents.

